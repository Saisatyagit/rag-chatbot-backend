// services/llmService.js
const { GoogleGenerativeAI } = require("@google/generative-ai");

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });

async function getLLMResponse(prompt) {
  try {
    const result = await model.generateContent(prompt);
    return result.response.text();
  } catch (err) {
    console.error("‚ùå Gemini Error:", err.message);
    return "Sorry, I had an issue fetching the response.";
  }
}

module.exports = { getLLMResponse };
